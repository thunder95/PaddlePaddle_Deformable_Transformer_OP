{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 模型介绍\n",
    "\n",
    "论文复现第三期DEFORMABLE DETR方案， 精确度MAP为0.446。本项目的一个亮点是基于paddlepaddle c++探索了可变形transformer自定义算子的实现。\n",
    "\n",
    "**DEFORMABLE TRANSFORMERS FOR END-TO-END OBJECT DETECTION**\n",
    "\n",
    "代码: [https://github.com/fundamentalvision/Deformable-DETR](https://github.com/fundamentalvision/Deformable-DETR)\n",
    "\n",
    "论文地址: [https://arxiv.org/pdf/2010.04159.pdf](https://arxiv.org/pdf/2010.04159.pdf)\n",
    "\n",
    "- 基于DETR，进行优化； DETR训练周期很长，比faster rcnn还慢10-20倍， 对小目标也不太优化\n",
    "- DETR直接使用特征图进行训练，Deformable DETR使用注意力后的特征图进行训练（即每一个query搜索有效位置作为keys）\n",
    "- 修改了key的提取方式，以及贡献图的生成方式，贡献图直接使用query的特征回归\n",
    "- backbone使用resnext101-DCN-trick， 提升了对小目标识别的性能\n",
    "- DETR的attention上权重过于均匀分布，导致需要训练更久去突出目标位置。所以本文对encoder在权重初始化时不再统一分布。deformable conv是一种更有效关注稀疏空间定位的方式， 对稀疏空间采样更友好， 在卷积上添加了位移变量， 这个变量根据数据的情况学习，偏移后，相当于卷积核每个方块可伸缩的变化，从而改变了感受野的范围，感受野成了一个多边形，同事对尺度和旋转变换起作用。\n",
    "- Deformable Attention Module，选取前2mk个通道编码采样的offset， 决定query去跟哪些key进行匹配。最后mk个通道计算keys的贡献。\n",
    "- 将deformable attention module扩展为多尺度feature map，主要解小目标问题，每一层采集K个点作为keys，转换成，对一个query，所有层均采K个点，融合了不同层的特征，故不需要FPN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 关于数据集COCO2017\n",
    "\n",
    "COCO的全称是Common Objects in Context，是微软团队提供的一个可以用来进行图像识别的数据集。MS COCO数据集中的图像分为训练、验证和测试集。其行业地位就不再多少了，本文主要梳理一下该数据集包含的内容。下图是官网给出的可下载的数据集（更新时间2020年01月09日），从这里可看出其数据集主要包括有标注的和无标注的数据。\n",
    "\n",
    "\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/fc21793a8cd6402a9c9d8b9e630fc06d6696c4fc98504c2b982840445aef44a3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#解压数据集\n",
    "%cd /home/aistudio/data/data7122/ \n",
    "!unzip train2017.zip\n",
    "!unzip val2017.zip \n",
    "!unzip annotations_trainval2017.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#加载数据集\n",
    "%cd ~/my_detr\n",
    "!python coco_dataset.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "deforamble_transformer# 模型结构搭建\n",
    "\n",
    "1. Backbone在resnet50基础上修改，支持DC5变体\n",
    "2. 搭建transformer结构\n",
    "3. 搭建后处理包括匈牙利匹配算法\n",
    "4. 损失函数\n",
    "4. 后处理\n",
    "\n",
    "\n",
    "**核心代码主要有:**\n",
    "* model.py\n",
    "* position_encoding.py, 暂时只用到了sine\n",
    "* resnet.py, 赞没用到dilation，返回的layers有变化\n",
    "* backbone.py， \n",
    "* deforamble_transformer.py\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/7542cd01503e46d1a80a33fbbd746d2d3d6c9fbc37ee44e7899c709b3701c1e2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 本地跑通pytorch代码\n",
    "\n",
    "`./configs/r50_deformable_detr.sh --eval`\n",
    "\n",
    "跑出的结果跟原作者发布的一致\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/536cbb7fdd2b4f1896918c561184cf67502b4e0fce9c455993d0d4bbbe24e81a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 使用x2paddle将torch代码转为paddle\n",
    "\n",
    "```\n",
    "pip install x2paddle --index https://pypi.python.org/simple/\n",
    "x2paddle --convert_torch_project --project_dir=Deformable-DETR --save_dir=paddle_project\n",
    "```\n",
    "\n",
    "**出现大量不支持的包和算子，所以暂时放弃，改用手动方式搭建**\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/87d4a80c2bd54b538eda17523e39e3e50eb8414930544145a13a075879787fc7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 添加自定义算子\n",
    "\n",
    "参照官方文档： [自定义外部算子](http://https://www.paddlepaddle.org.cn/documentation/docs/zh/guides/07_new_op/new_custom_op_cn.html)\n",
    "\n",
    "参考pytorch对算子的实现，主要完成forward和backward计算逻辑， 接口封装时需要严格安装官方文档编写，如Attribute声明， 返回数据的shape和dtype定义等等。\n",
    "\n",
    "运行方式可以直接通过setup安装到pip环境，也可以JIT运行时编译， 本项目采用第二种。\n",
    "\n",
    "**下列命令是对torch的模拟输入在paddle中进行验证， 前向和反向输出结果一致。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/my_df_detr/ops\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:26: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def convert_to_list(value, n, name, dtype=np.int):\n",
      "Compiling user custom op, it will cost a few seconds.....\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:26: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def convert_to_list(value, n, name, dtype=np.int):\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:77: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  return (isinstance(seq, collections.Sequence) and\n",
      "2021-05-28 14:35:58,059 - INFO - Re-Compiling custom_jit_ops.so, because specified cflags have been changed. New signature c362299a2c5efc8bf87b48534e812379 has been saved into /home/aistudio/.cache/paddle_extensions/custom_jit_ops/version.txt.\n",
      "\u001b[01m\u001b[Kcc1plus:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcommand line option ‘\u001b[01m\u001b[K-Wstrict-prototypes\u001b[m\u001b[K’ is valid for C/ObjC but not for C++\n",
      "value type <class 'paddle.VarBase'>\n",
      "shapes type <class 'paddle.VarBase'>\n",
      "level_start_index type <class 'paddle.VarBase'>\n",
      "sampling_locations type <class 'paddle.VarBase'>\n",
      "attention_weights type <class 'paddle.VarBase'>\n",
      "im2col_step type <class 'int'>\n",
      "W0528 14:36:09.285770  1804 device_context.cc:362] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.0, Runtime API Version: 10.1\n",
      "W0528 14:36:09.290293  1804 device_context.cc:372] device: 0, cuDNN Version: 7.6.\n",
      "paddle output [[[0.00189938 0.00460283 0.00467118 0.0043844 ]\n",
      "  [0.0037951  0.00251276 0.00184443 0.00363468]]]\n",
      "torch output:  [[[0.00189938 0.00460283 0.00467118 0.0043844 ]\n",
      "  [0.0037951  0.00251276 0.00184443 0.00363468]]]\n",
      "all test ok\n"
     ]
    }
   ],
   "source": [
    "%cd ~/my_df_detr/ops\n",
    "!python ms_deform_attn_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 搭建模型结构\n",
    "\n",
    "其中几大核心模块主要包括构建backbone, transformer, position encoding, hungrimatcher等等。 可直接运行以下命令查看网络结构："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/my_df_detr\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:26: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def convert_to_list(value, n, name, dtype=np.int):\n",
      "/home/aistudio/my_df_detr/deformable_transformer.py:137: DeprecationWarning: invalid escape sequence \\s\n",
      "  \"\"\"\n",
      "/home/aistudio/my_df_detr/paddle_utils.py:113: DeprecationWarning: invalid escape sequence \\m\n",
      "  \"\"\"\n",
      "Compiling user custom op, it will cost a few seconds.....\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:26: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def convert_to_list(value, n, name, dtype=np.int):\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:77: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  return (isinstance(seq, collections.Sequence) and\n",
      "2021-05-28 14:41:18,674 - INFO - Re-Compiling custom_jit_ops.so, because specified cflags have been changed. New signature cae118c821a2806df1b811169cc15250 has been saved into /home/aistudio/.cache/paddle_extensions/custom_jit_ops/version.txt.\n",
      "\u001b[01m\u001b[Kcc1plus:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcommand line option ‘\u001b[01m\u001b[K-Wstrict-prototypes\u001b[m\u001b[K’ is valid for C/ObjC but not for C++\n",
      "Namespace(aux_loss=True, backbone='resnet50', batch_size=1, bbox_loss_coef=5, cache_mode=False, clip_max_norm=0.1, cls_loss_coef=2, coco_panoptic_path=None, coco_path='/f/dataset/COCO2017', dataset_file='coco', dec_layers=6, dec_n_points=4, device='cuda', dice_loss_coef=1, dilation=False, dim_feedforward=1024, dropout=0.1, enc_layers=6, enc_n_points=4, epochs=5, eval=True, focal_alpha=0.25, frozen_weights=None, giou_loss_coef=2, hidden_dim=256, lr=0.0002, lr_backbone=2e-05, lr_backbone_names=['backbone.0'], lr_drop=40, lr_drop_epochs=None, lr_linear_proj_mult=0.1, lr_linear_proj_names=['reference_points', 'sampling_offsets'], mask_loss_coef=1, masks=False, nheads=8, num_feature_levels=4, num_queries=300, num_workers=0, output_dir='', position_embedding='sine', position_embedding_scale=6.283185307179586, remove_difficult=False, resume='r50_deformable_detr-checkpoint.pth', seed=42, set_cost_bbox=5, set_cost_class=2, set_cost_giou=2, sgd=False, start_epoch=0, two_stage=False, weight_decay=0.0001, with_box_refine=False)\n",
      "W0528 14:41:30.164860  2508 device_context.cc:362] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.0, Runtime API Version: 10.1\n",
      "W0528 14:41:30.170346  2508 device_context.cc:372] device: 0, cuDNN Version: 7.6.\n",
      "DeformableDETR(\n",
      "  (transformer): DeformableTransformer(\n",
      "    (encoder): DeformableTransformerEncoder(\n",
      "      (layers): LayerList(\n",
      "        (0): DeformableTransformerEncoderLayer(\n",
      "          (self_attn): MSDeformAttn(\n",
      "            (sampling_offsets): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "            (attention_weights): Linear(in_features=256, out_features=128, dtype=float32)\n",
      "            (value_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "            (output_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "          )\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (norm1): LayerNorm(normalized_shape=[256], epsilon=1e-05)\n",
      "          (linear1): Linear(in_features=256, out_features=1024, dtype=float32)\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=1024, out_features=256, dtype=float32)\n",
      "          (dropout3): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (norm2): LayerNorm(normalized_shape=[256], epsilon=1e-05)\n",
      "        )\n",
      "        (1): DeformableTransformerEncoderLayer(\n",
      "          (self_attn): MSDeformAttn(\n",
      "            (sampling_offsets): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "            (attention_weights): Linear(in_features=256, out_features=128, dtype=float32)\n",
      "            (value_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "            (output_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "          )\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (norm1): LayerNorm(normalized_shape=[256], epsilon=1e-05)\n",
      "          (linear1): Linear(in_features=256, out_features=1024, dtype=float32)\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=1024, out_features=256, dtype=float32)\n",
      "          (dropout3): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (norm2): LayerNorm(normalized_shape=[256], epsilon=1e-05)\n",
      "        )\n",
      "        (2): DeformableTransformerEncoderLayer(\n",
      "          (self_attn): MSDeformAttn(\n",
      "            (sampling_offsets): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "            (attention_weights): Linear(in_features=256, out_features=128, dtype=float32)\n",
      "            (value_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "            (output_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "          )\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (norm1): LayerNorm(normalized_shape=[256], epsilon=1e-05)\n",
      "          (linear1): Linear(in_features=256, out_features=1024, dtype=float32)\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=1024, out_features=256, dtype=float32)\n",
      "          (dropout3): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (norm2): LayerNorm(normalized_shape=[256], epsilon=1e-05)\n",
      "        )\n",
      "        (3): DeformableTransformerEncoderLayer(\n",
      "          (self_attn): MSDeformAttn(\n",
      "            (sampling_offsets): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "            (attention_weights): Linear(in_features=256, out_features=128, dtype=float32)\n",
      "            (value_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "            (output_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "          )\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (norm1): LayerNorm(normalized_shape=[256], epsilon=1e-05)\n",
      "          (linear1): Linear(in_features=256, out_features=1024, dtype=float32)\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=1024, out_features=256, dtype=float32)\n",
      "          (dropout3): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (norm2): LayerNorm(normalized_shape=[256], epsilon=1e-05)\n",
      "        )\n",
      "        (4): DeformableTransformerEncoderLayer(\n",
      "          (self_attn): MSDeformAttn(\n",
      "            (sampling_offsets): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "            (attention_weights): Linear(in_features=256, out_features=128, dtype=float32)\n",
      "            (value_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "            (output_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "          )\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (norm1): LayerNorm(normalized_shape=[256], epsilon=1e-05)\n",
      "          (linear1): Linear(in_features=256, out_features=1024, dtype=float32)\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=1024, out_features=256, dtype=float32)\n",
      "          (dropout3): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (norm2): LayerNorm(normalized_shape=[256], epsilon=1e-05)\n",
      "        )\n",
      "        (5): DeformableTransformerEncoderLayer(\n",
      "          (self_attn): MSDeformAttn(\n",
      "            (sampling_offsets): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "            (attention_weights): Linear(in_features=256, out_features=128, dtype=float32)\n",
      "            (value_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "            (output_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "          )\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (norm1): LayerNorm(normalized_shape=[256], epsilon=1e-05)\n",
      "          (linear1): Linear(in_features=256, out_features=1024, dtype=float32)\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=1024, out_features=256, dtype=float32)\n",
      "          (dropout3): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (norm2): LayerNorm(normalized_shape=[256], epsilon=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (decoder): DeformableTransformerDecoder(\n",
      "      (layers): LayerList(\n",
      "        (0): DeformableTransformerDecoderLayer(\n",
      "          (cross_attn): MSDeformAttn(\n",
      "            (sampling_offsets): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "            (attention_weights): Linear(in_features=256, out_features=128, dtype=float32)\n",
      "            (value_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "            (output_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "          )\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (norm1): LayerNorm(normalized_shape=[256], epsilon=1e-05)\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (q_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "            (k_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "            (v_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "            (out_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "          )\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (norm2): LayerNorm(normalized_shape=[256], epsilon=1e-05)\n",
      "          (linear1): Linear(in_features=256, out_features=1024, dtype=float32)\n",
      "          (dropout3): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=1024, out_features=256, dtype=float32)\n",
      "          (dropout4): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (norm3): LayerNorm(normalized_shape=[256], epsilon=1e-05)\n",
      "        )\n",
      "        (1): DeformableTransformerDecoderLayer(\n",
      "          (cross_attn): MSDeformAttn(\n",
      "            (sampling_offsets): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "            (attention_weights): Linear(in_features=256, out_features=128, dtype=float32)\n",
      "            (value_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "            (output_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "          )\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (norm1): LayerNorm(normalized_shape=[256], epsilon=1e-05)\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (q_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "            (k_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "            (v_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "            (out_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "          )\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (norm2): LayerNorm(normalized_shape=[256], epsilon=1e-05)\n",
      "          (linear1): Linear(in_features=256, out_features=1024, dtype=float32)\n",
      "          (dropout3): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=1024, out_features=256, dtype=float32)\n",
      "          (dropout4): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (norm3): LayerNorm(normalized_shape=[256], epsilon=1e-05)\n",
      "        )\n",
      "        (2): DeformableTransformerDecoderLayer(\n",
      "          (cross_attn): MSDeformAttn(\n",
      "            (sampling_offsets): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "            (attention_weights): Linear(in_features=256, out_features=128, dtype=float32)\n",
      "            (value_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "            (output_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "          )\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (norm1): LayerNorm(normalized_shape=[256], epsilon=1e-05)\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (q_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "            (k_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "            (v_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "            (out_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "          )\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (norm2): LayerNorm(normalized_shape=[256], epsilon=1e-05)\n",
      "          (linear1): Linear(in_features=256, out_features=1024, dtype=float32)\n",
      "          (dropout3): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=1024, out_features=256, dtype=float32)\n",
      "          (dropout4): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (norm3): LayerNorm(normalized_shape=[256], epsilon=1e-05)\n",
      "        )\n",
      "        (3): DeformableTransformerDecoderLayer(\n",
      "          (cross_attn): MSDeformAttn(\n",
      "            (sampling_offsets): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "            (attention_weights): Linear(in_features=256, out_features=128, dtype=float32)\n",
      "            (value_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "            (output_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "          )\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (norm1): LayerNorm(normalized_shape=[256], epsilon=1e-05)\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (q_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "            (k_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "            (v_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "            (out_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "          )\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (norm2): LayerNorm(normalized_shape=[256], epsilon=1e-05)\n",
      "          (linear1): Linear(in_features=256, out_features=1024, dtype=float32)\n",
      "          (dropout3): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=1024, out_features=256, dtype=float32)\n",
      "          (dropout4): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (norm3): LayerNorm(normalized_shape=[256], epsilon=1e-05)\n",
      "        )\n",
      "        (4): DeformableTransformerDecoderLayer(\n",
      "          (cross_attn): MSDeformAttn(\n",
      "            (sampling_offsets): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "            (attention_weights): Linear(in_features=256, out_features=128, dtype=float32)\n",
      "            (value_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "            (output_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "          )\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (norm1): LayerNorm(normalized_shape=[256], epsilon=1e-05)\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (q_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "            (k_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "            (v_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "            (out_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "          )\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (norm2): LayerNorm(normalized_shape=[256], epsilon=1e-05)\n",
      "          (linear1): Linear(in_features=256, out_features=1024, dtype=float32)\n",
      "          (dropout3): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=1024, out_features=256, dtype=float32)\n",
      "          (dropout4): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (norm3): LayerNorm(normalized_shape=[256], epsilon=1e-05)\n",
      "        )\n",
      "        (5): DeformableTransformerDecoderLayer(\n",
      "          (cross_attn): MSDeformAttn(\n",
      "            (sampling_offsets): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "            (attention_weights): Linear(in_features=256, out_features=128, dtype=float32)\n",
      "            (value_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "            (output_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "          )\n",
      "          (dropout1): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (norm1): LayerNorm(normalized_shape=[256], epsilon=1e-05)\n",
      "          (self_attn): MultiHeadAttention(\n",
      "            (q_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "            (k_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "            (v_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "            (out_proj): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "          )\n",
      "          (dropout2): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (norm2): LayerNorm(normalized_shape=[256], epsilon=1e-05)\n",
      "          (linear1): Linear(in_features=256, out_features=1024, dtype=float32)\n",
      "          (dropout3): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (linear2): Linear(in_features=1024, out_features=256, dtype=float32)\n",
      "          (dropout4): Dropout(p=0.1, axis=None, mode=upscale_in_train)\n",
      "          (norm3): LayerNorm(normalized_shape=[256], epsilon=1e-05)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (reference_points): Linear(in_features=256, out_features=2, dtype=float32)\n",
      "  )\n",
      "  (class_embed): LayerList(\n",
      "    (0): Linear(in_features=256, out_features=91, dtype=float32)\n",
      "    (1): Linear(in_features=256, out_features=91, dtype=float32)\n",
      "    (2): Linear(in_features=256, out_features=91, dtype=float32)\n",
      "    (3): Linear(in_features=256, out_features=91, dtype=float32)\n",
      "    (4): Linear(in_features=256, out_features=91, dtype=float32)\n",
      "    (5): Linear(in_features=256, out_features=91, dtype=float32)\n",
      "  )\n",
      "  (bbox_embed): LayerList(\n",
      "    (0): MLP(\n",
      "      (layers): LayerList(\n",
      "        (0): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "        (1): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "        (2): Linear(in_features=256, out_features=4, dtype=float32)\n",
      "      )\n",
      "    )\n",
      "    (1): MLP(\n",
      "      (layers): LayerList(\n",
      "        (0): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "        (1): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "        (2): Linear(in_features=256, out_features=4, dtype=float32)\n",
      "      )\n",
      "    )\n",
      "    (2): MLP(\n",
      "      (layers): LayerList(\n",
      "        (0): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "        (1): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "        (2): Linear(in_features=256, out_features=4, dtype=float32)\n",
      "      )\n",
      "    )\n",
      "    (3): MLP(\n",
      "      (layers): LayerList(\n",
      "        (0): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "        (1): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "        (2): Linear(in_features=256, out_features=4, dtype=float32)\n",
      "      )\n",
      "    )\n",
      "    (4): MLP(\n",
      "      (layers): LayerList(\n",
      "        (0): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "        (1): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "        (2): Linear(in_features=256, out_features=4, dtype=float32)\n",
      "      )\n",
      "    )\n",
      "    (5): MLP(\n",
      "      (layers): LayerList(\n",
      "        (0): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "        (1): Linear(in_features=256, out_features=256, dtype=float32)\n",
      "        (2): Linear(in_features=256, out_features=4, dtype=float32)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (query_embed): Embedding(300, 512, sparse=False)\n",
      "  (input_proj): LayerList(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2D(512, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "      (1): GroupNorm(num_groups=32, num_channels=256, epsilon=1e-05)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "      (1): GroupNorm(num_groups=32, num_channels=256, epsilon=1e-05)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Conv2D(2048, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "      (1): GroupNorm(num_groups=32, num_channels=256, epsilon=1e-05)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Conv2D(2048, 256, kernel_size=[3, 3], stride=[2, 2], padding=1, data_format=NCHW)\n",
      "      (1): GroupNorm(num_groups=32, num_channels=256, epsilon=1e-05)\n",
      "    )\n",
      "  )\n",
      "  (backbone): Joiner(\n",
      "    (0): Backbone(\n",
      "      (body): IntermediateLayerGetter(\n",
      "        (conv1): Conv2D(3, 64, kernel_size=[7, 7], stride=[2, 2], padding=3, data_format=NCHW)\n",
      "        (bn1): FrozenBatchNorm2d(\n",
      "          (module): BatchNorm()\n",
      "        )\n",
      "        (relu): ReLU()\n",
      "        (maxpool): MaxPool2D(kernel_size=3, stride=2, padding=1)\n",
      "        (layer1): Sequential(\n",
      "          (0): BottleneckBlock(\n",
      "            (conv1): Conv2D(64, 64, kernel_size=[1, 1], data_format=NCHW)\n",
      "            (bn1): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (conv2): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "            (bn2): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (conv3): Conv2D(64, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "            (bn3): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (relu): ReLU()\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2D(64, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "              (1): FrozenBatchNorm2d(\n",
      "                (module): BatchNorm()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): BottleneckBlock(\n",
      "            (conv1): Conv2D(256, 64, kernel_size=[1, 1], data_format=NCHW)\n",
      "            (bn1): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (conv2): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "            (bn2): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (conv3): Conv2D(64, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "            (bn3): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (relu): ReLU()\n",
      "          )\n",
      "          (2): BottleneckBlock(\n",
      "            (conv1): Conv2D(256, 64, kernel_size=[1, 1], data_format=NCHW)\n",
      "            (bn1): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (conv2): Conv2D(64, 64, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "            (bn2): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (conv3): Conv2D(64, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "            (bn3): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (relu): ReLU()\n",
      "          )\n",
      "        )\n",
      "        (layer2): Sequential(\n",
      "          (0): BottleneckBlock(\n",
      "            (conv1): Conv2D(256, 128, kernel_size=[1, 1], data_format=NCHW)\n",
      "            (bn1): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (conv2): Conv2D(128, 128, kernel_size=[3, 3], stride=[2, 2], padding=1, data_format=NCHW)\n",
      "            (bn2): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (conv3): Conv2D(128, 512, kernel_size=[1, 1], data_format=NCHW)\n",
      "            (bn3): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (relu): ReLU()\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2D(256, 512, kernel_size=[1, 1], stride=[2, 2], data_format=NCHW)\n",
      "              (1): FrozenBatchNorm2d(\n",
      "                (module): BatchNorm()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): BottleneckBlock(\n",
      "            (conv1): Conv2D(512, 128, kernel_size=[1, 1], data_format=NCHW)\n",
      "            (bn1): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (conv2): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "            (bn2): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (conv3): Conv2D(128, 512, kernel_size=[1, 1], data_format=NCHW)\n",
      "            (bn3): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (relu): ReLU()\n",
      "          )\n",
      "          (2): BottleneckBlock(\n",
      "            (conv1): Conv2D(512, 128, kernel_size=[1, 1], data_format=NCHW)\n",
      "            (bn1): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (conv2): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "            (bn2): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (conv3): Conv2D(128, 512, kernel_size=[1, 1], data_format=NCHW)\n",
      "            (bn3): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (relu): ReLU()\n",
      "          )\n",
      "          (3): BottleneckBlock(\n",
      "            (conv1): Conv2D(512, 128, kernel_size=[1, 1], data_format=NCHW)\n",
      "            (bn1): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (conv2): Conv2D(128, 128, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "            (bn2): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (conv3): Conv2D(128, 512, kernel_size=[1, 1], data_format=NCHW)\n",
      "            (bn3): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (relu): ReLU()\n",
      "          )\n",
      "        )\n",
      "        (layer3): Sequential(\n",
      "          (0): BottleneckBlock(\n",
      "            (conv1): Conv2D(512, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "            (bn1): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (conv2): Conv2D(256, 256, kernel_size=[3, 3], stride=[2, 2], padding=1, data_format=NCHW)\n",
      "            (bn2): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "            (bn3): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (relu): ReLU()\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2D(512, 1024, kernel_size=[1, 1], stride=[2, 2], data_format=NCHW)\n",
      "              (1): FrozenBatchNorm2d(\n",
      "                (module): BatchNorm()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): BottleneckBlock(\n",
      "            (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "            (bn1): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "            (bn2): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "            (bn3): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (relu): ReLU()\n",
      "          )\n",
      "          (2): BottleneckBlock(\n",
      "            (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "            (bn1): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "            (bn2): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "            (bn3): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (relu): ReLU()\n",
      "          )\n",
      "          (3): BottleneckBlock(\n",
      "            (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "            (bn1): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "            (bn2): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "            (bn3): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (relu): ReLU()\n",
      "          )\n",
      "          (4): BottleneckBlock(\n",
      "            (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "            (bn1): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "            (bn2): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "            (bn3): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (relu): ReLU()\n",
      "          )\n",
      "          (5): BottleneckBlock(\n",
      "            (conv1): Conv2D(1024, 256, kernel_size=[1, 1], data_format=NCHW)\n",
      "            (bn1): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (conv2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "            (bn2): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (conv3): Conv2D(256, 1024, kernel_size=[1, 1], data_format=NCHW)\n",
      "            (bn3): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (relu): ReLU()\n",
      "          )\n",
      "        )\n",
      "        (layer4): Sequential(\n",
      "          (0): BottleneckBlock(\n",
      "            (conv1): Conv2D(1024, 512, kernel_size=[1, 1], data_format=NCHW)\n",
      "            (bn1): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (conv2): Conv2D(512, 512, kernel_size=[3, 3], stride=[2, 2], padding=1, data_format=NCHW)\n",
      "            (bn2): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (conv3): Conv2D(512, 2048, kernel_size=[1, 1], data_format=NCHW)\n",
      "            (bn3): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (relu): ReLU()\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2D(1024, 2048, kernel_size=[1, 1], stride=[2, 2], data_format=NCHW)\n",
      "              (1): FrozenBatchNorm2d(\n",
      "                (module): BatchNorm()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): BottleneckBlock(\n",
      "            (conv1): Conv2D(2048, 512, kernel_size=[1, 1], data_format=NCHW)\n",
      "            (bn1): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (conv2): Conv2D(512, 512, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "            (bn2): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (conv3): Conv2D(512, 2048, kernel_size=[1, 1], data_format=NCHW)\n",
      "            (bn3): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (relu): ReLU()\n",
      "          )\n",
      "          (2): BottleneckBlock(\n",
      "            (conv1): Conv2D(2048, 512, kernel_size=[1, 1], data_format=NCHW)\n",
      "            (bn1): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (conv2): Conv2D(512, 512, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
      "            (bn2): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (conv3): Conv2D(512, 2048, kernel_size=[1, 1], data_format=NCHW)\n",
      "            (bn3): FrozenBatchNorm2d(\n",
      "              (module): BatchNorm()\n",
      "            )\n",
      "            (relu): ReLU()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): PositionEmbeddingSine()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "%cd ~/my_df_detr\n",
    "!python model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 权重转换\n",
    "\n",
    "将pytorch的权重转到paddle， 里面有几个地方需要注意: \n",
    "- 拆分多头注意力机制中的QKV权重\n",
    "- BN层权重名称转换\n",
    "- 全连接层权重维度转置\n",
    "\n",
    "```\n",
    "def convert_param_dict(model_dict, trans_weights):\n",
    "    renamed_state_dict = {}\n",
    "    for k, v in model_dict.items():\n",
    "        name_list = k.split('.')\n",
    "        if k in trans_weights:\n",
    "            renamed_state_dict[k] = v.numpy().transpose((1, 0))\n",
    "            continue\n",
    "\n",
    "        if len(name_list) > 2 and name_list[-2][:2] == 'bn':\n",
    "            if name_list[-1] == \"weight\":\n",
    "                ender = \"weight\"\n",
    "            elif name_list[-1] == \"bias\":\n",
    "                ender = \"bias\"\n",
    "            elif name_list[-1] == \"running_mean\":\n",
    "                ender = \"_mean\"\n",
    "            elif name_list[-1] == \"running_var\":\n",
    "                ender = \"_variance\"\n",
    "            new_k = name_list[:-1] + [\"module\", ender]\n",
    "            renamed_state_dict['.'.join(new_k)] = v.numpy()\n",
    "\n",
    "        elif len(name_list) > 2 and name_list[-2][:6] == 'linear' and name_list[-1] == \"weight\":\n",
    "            renamed_state_dict['.'.join(name_list)] = v.numpy().transpose((1, 0))\n",
    "\n",
    "        elif len(name_list) >= 2 and name_list[0][-5:] == \"embed\" and name_list[0][0] != 'q' \\\n",
    "                and name_list[-1] == \"weight\":\n",
    "            renamed_state_dict['.'.join(name_list)] = v.numpy().transpose((1, 0))\n",
    "\n",
    "        elif len(name_list) > 2 and (name_list[-2] == 'self_attn' or name_list[-2] == 'multihead_attn'):\n",
    "            if name_list[-1][-4:] == \"bias\":\n",
    "                q_v, k_v, v_v = np.split(v.numpy(), 3)\n",
    "                q_k = name_list[:-1] + [\"q_proj\", \"bias\"]\n",
    "                k_k = name_list[:-1] + [\"k_proj\", \"bias\"]\n",
    "                v_k = name_list[:-1] + [\"v_proj\", \"bias\"]\n",
    "                renamed_state_dict['.'.join(q_k)] = q_v\n",
    "                renamed_state_dict['.'.join(k_k)] = k_v\n",
    "                renamed_state_dict['.'.join(v_k)] = v_v\n",
    "            else:\n",
    "                q_v, k_v, v_v = np.split(v.numpy().transpose((1, 0)), 3, axis=1)\n",
    "                # q_v, k_v, v_v = np.split(v.numpy(), 3, axis = 0)\n",
    "                q_k = name_list[:-1] + [\"q_proj\", \"weight\"]\n",
    "                k_k = name_list[:-1] + [\"k_proj\", \"weight\"]\n",
    "                v_k = name_list[:-1] + [\"v_proj\", \"weight\"]\n",
    "                renamed_state_dict['.'.join(q_k)] = q_v\n",
    "                renamed_state_dict['.'.join(k_k)] = k_v\n",
    "                renamed_state_dict['.'.join(v_k)] = v_v\n",
    "\n",
    "        elif len(name_list) > 2 and (name_list[-3] == 'self_attn' or name_list[-3] == 'multihead_attn'):\n",
    "            if name_list[-1][-4:] == \"bias\":\n",
    "                renamed_state_dict['.'.join(name_list)] = v.numpy()\n",
    "            else:\n",
    "                renamed_state_dict['.'.join(name_list)] = v.numpy().transpose((1, 0))\n",
    "\n",
    "        elif len(name_list) > 3 and name_list[-3] == 'downsample' and name_list[-2] == '1':\n",
    "            if name_list[-1] == \"weight\":\n",
    "                ender = \"weight\"\n",
    "            elif name_list[-1] == \"bias\":\n",
    "                ender = \"bias\"\n",
    "            elif name_list[-1] == \"running_mean\":\n",
    "                ender = \"_mean\"\n",
    "            elif name_list[-1] == \"running_var\":\n",
    "                ender = \"_variance\"\n",
    "            new_k = name_list[:-1] + [\"module\", ender]\n",
    "            renamed_state_dict['.'.join(new_k)] = v.numpy()\n",
    "\n",
    "        else:\n",
    "            renamed_state_dict[k] = v.numpy()\n",
    "\n",
    "    return renamed_state_dict\n",
    "\n",
    "\n",
    "device = torch.device(args.device)\n",
    "seed = args.seed + utils.get_rank()\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "model, criterion, postprocessors = build_model(args)\n",
    "model.to(device)\n",
    "\n",
    "if args.resume:\n",
    "    if args.resume.startswith('https'):\n",
    "        checkpoint = torch.hub.load_state_dict_from_url(\n",
    "            args.resume, map_location='cpu', check_hash=True)\n",
    "    else:\n",
    "        checkpoint = torch.load(args.resume, map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "trans_weights = []\n",
    "for layer in model.named_modules():\n",
    "    if isinstance(layer[1], torch.nn.Linear):\n",
    "        trans_weights.append(layer[0] + \".weight\")\n",
    "\n",
    "model_state_dict = convert_param_dict(model.state_dict(), trans_weights)\n",
    "f = open(\"df_wts_dc5.pkl\", \"wb\")\n",
    "pickle.dump(model_state_dict, f)\n",
    "f.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 用预训练模型验证\n",
    "\n",
    "用转换的权重对模型进行验证，基本能达到torch的精度， **44.6高于原作者官方给出的44.5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/my_df_detr\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:26: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def convert_to_list(value, n, name, dtype=np.int):\n",
      "/home/aistudio/my_df_detr/deformable_transformer.py:137: DeprecationWarning: invalid escape sequence \\s\n",
      "  \"\"\"\n",
      "Compiling user custom op, it will cost a few seconds.....\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:26: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def convert_to_list(value, n, name, dtype=np.int):\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:77: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  return (isinstance(seq, collections.Sequence) and\n",
      "2021-05-28 14:55:53,645 - INFO - Re-Compiling custom_jit_ops.so, because specified cflags have been changed. New signature c362299a2c5efc8bf87b48534e812379 has been saved into /home/aistudio/.cache/paddle_extensions/custom_jit_ops/version.txt.\n",
      "\u001b[01m\u001b[Kcc1plus:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kcommand line option ‘\u001b[01m\u001b[K-Wstrict-prototypes\u001b[m\u001b[K’ is valid for C/ObjC but not for C++\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py:107: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import MutableMapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable, Mapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sized\n",
      "Namespace(aux_loss=True, backbone='resnet50', batch_size=1, bbox_loss_coef=5, cache_mode=False, clip_max_norm=0.1, cls_loss_coef=2, coco_panoptic_path=None, coco_path='/home/aistudio/data/data7122', dataset_file='coco', dec_layers=6, dec_n_points=4, device='cuda', dice_loss_coef=1, dilation=False, dim_feedforward=1024, dropout=0.1, enc_layers=6, enc_n_points=4, epochs=5, eval=True, focal_alpha=0.25, frozen_weights=None, giou_loss_coef=2, hidden_dim=256, lr=0.0002, lr_backbone=2e-05, lr_backbone_names=['backbone.0'], lr_drop=40, lr_drop_epochs=None, lr_linear_proj_mult=0.1, lr_linear_proj_names=['reference_points', 'sampling_offsets'], mask_loss_coef=1, masks=False, nheads=8, num_feature_levels=4, num_queries=300, num_workers=0, output_dir='', position_embedding='sine', position_embedding_scale=6.283185307179586, remove_difficult=False, resume='r50_deformable_detr-checkpoint.pth', seed=42, set_cost_bbox=5, set_cost_class=2, set_cost_giou=2, sgd=False, start_epoch=0, two_stage=False, weight_decay=0.0001, with_box_refine=False)\n",
      "W0528 14:56:06.356289  4282 device_context.cc:362] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.0, Runtime API Version: 10.1\n",
      "W0528 14:56:06.361850  4282 device_context.cc:372] device: 0, cuDNN Version: 7.6.\n",
      "Epoch 0: StepDecay set learning rate to 0.0002.\n",
      "loading annotations into memory...\n",
      "Done (t=0.61s)\n",
      "creating index...\n",
      "index created!\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/tensor/creation.py:143: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if data.dtype == np.object:\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py:687: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  elif dtype == np.bool:\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/math_op_patch.py:238: UserWarning: The dtype of left and right variables are not the same, left dtype is VarType.FP32, but right dtype is VarType.INT64, the right dtype will convert to VarType.FP32\n",
      "  format(lhs_dtype, rhs_dtype, lhs_dtype))\n",
      "Accumulating evaluation results...\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pycocotools/cocoeval.py:378: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  tp_sum = np.cumsum(tps, axis=1).astype(dtype=np.float)\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pycocotools/cocoeval.py:379: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  fp_sum = np.cumsum(fps, axis=1).astype(dtype=np.float)\n",
      "DONE (t=17.32s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.446\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.637\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.487\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.268\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.477\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.596\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.352\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.588\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.629\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.419\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.673\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.818\n"
     ]
    }
   ],
   "source": [
    "%cd ~/my_df_detr\n",
    "!python train_val.py --eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 数据预处理对齐\n",
    "\n",
    "对于样例图片进行预处理后，送入到网络中的数据基本保持一致。\n",
    "\n",
    "**torch输出如下:**\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/4a6a0aa74eec42d098020f3abc053101bb48cf86036f4ce48fd9bc5265d045f0)\n",
    "\n",
    "\n",
    "**paddle输出如下:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/my_df_detr\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:26: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def convert_to_list(value, n, name, dtype=np.int):\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py:107: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import MutableMapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable, Mapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sized\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/tensor/creation.py:143: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if data.dtype == np.object:\n",
      "W0528 15:16:05.932473  6457 device_context.cc:362] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.0, Runtime API Version: 10.1\n",
      "W0528 15:16:05.937321  6457 device_context.cc:372] device: 0, cuDNN Version: 7.6.\n",
      "[Tensor(shape=[3, 800, 1199], dtype=float64, place=CUDAPlace(0), stop_gradient=True,\n",
      "       [[[ 0.00556555, -0.01155920, -0.04580871, ..., -1.96378114, -1.92953163, -1.91240688],\n",
      "         [-0.04580871, -0.04580871, -0.06293346, ..., -1.96378114, -1.92953163, -1.91240688],\n",
      "         [-0.13143247, -0.09718297, -0.08005822, ..., -1.94665639, -1.92953163, -1.92953163],\n",
      "         ...,\n",
      "         [ 0.27956172,  0.29668648,  0.33093598, ..., -1.27879098, -1.31304048, -1.33016524],\n",
      "         [ 0.29668648,  0.31381123,  0.34806073, ..., -1.26166622, -1.29591573, -1.29591573],\n",
      "         [ 0.31381123,  0.33093598,  0.34806073, ..., -1.26166622, -1.27879098, -1.27879098]],\n",
      "\n",
      "        [[ 0.20518221,  0.18767507,  0.17016807, ..., -1.86064425, -1.82563025, -1.80812325],\n",
      "         [ 0.22268921,  0.22268921,  0.22268921, ..., -1.86064425, -1.82563025, -1.82563025],\n",
      "         [ 0.25770321,  0.27521021,  0.31022422, ..., -1.86064425, -1.84313725, -1.84313725],\n",
      "         ...,\n",
      "         [-0.19747897, -0.17997197, -0.14495796, ..., -1.49299720, -1.47549016, -1.47549016],\n",
      "         [-0.16246496, -0.14495796, -0.12745096, ..., -1.47549016, -1.47549016, -1.47549016],\n",
      "         [-0.14495796, -0.12745096, -0.10994396, ..., -1.47549016, -1.47549016, -1.47549016]],\n",
      "\n",
      "        [[-0.46239646, -0.53211323, -0.65411758, ..., -1.59529411, -1.56043573, -1.54300653],\n",
      "         [-0.51468404, -0.54954243, -0.61925920, ..., -1.61272331, -1.59529411, -1.57786492],\n",
      "         [-0.60183000, -0.58440081, -0.56697162, ..., -1.63015250, -1.63015250, -1.63015250],\n",
      "         ...,\n",
      "         [-0.53211323, -0.51468404, -0.47982565, ..., -1.38614378, -1.40357298, -1.40357298],\n",
      "         [-0.54954243, -0.53211323, -0.49725485, ..., -1.40357298, -1.42100217, -1.42100217],\n",
      "         [-0.56697162, -0.54954243, -0.51468404, ..., -1.42100217, -1.42100217, -1.42100217]]])]\n"
     ]
    }
   ],
   "source": [
    "%cd ~/my_df_detr\n",
    "!python check_image_pre.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 前向输出对齐\n",
    "\n",
    "输入1*3*800*1199的模拟数据(ones), 对比torch以及Paddle的输出。 已在debug窗口进行对比过， 输出基本一致， 这里以pred_logits输出为例。\n",
    "\n",
    "**torch输出如下:**\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/9ad659fb46db498eb958359bd70104eb39636bbf2c51444c84ed7d122bdbae67)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/my_df_detr\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:26: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def convert_to_list(value, n, name, dtype=np.int):\n",
      "Compiling user custom op, it will cost a few seconds.....\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:26: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def convert_to_list(value, n, name, dtype=np.int):\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:77: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  return (isinstance(seq, collections.Sequence) and\n",
      "Namespace(aux_loss=True, backbone='resnet50', batch_size=1, bbox_loss_coef=5, cache_mode=False, clip_max_norm=0.1, cls_loss_coef=2, coco_panoptic_path=None, coco_path='/home/aistudio/data/data7122', dataset_file='coco', dec_layers=6, dec_n_points=4, device='cuda', dice_loss_coef=1, dilation=False, dim_feedforward=1024, dropout=0.1, enc_layers=6, enc_n_points=4, epochs=5, eval=True, focal_alpha=0.25, frozen_weights=None, giou_loss_coef=2, hidden_dim=256, lr=0.0002, lr_backbone=2e-05, lr_backbone_names=['backbone.0'], lr_drop=40, lr_drop_epochs=None, lr_linear_proj_mult=0.1, lr_linear_proj_names=['reference_points', 'sampling_offsets'], mask_loss_coef=1, masks=False, nheads=8, num_feature_levels=4, num_queries=300, num_workers=0, output_dir='', position_embedding='sine', position_embedding_scale=6.283185307179586, remove_difficult=False, resume='r50_deformable_detr-checkpoint.pth', seed=42, set_cost_bbox=5, set_cost_class=2, set_cost_giou=2, sgd=False, start_epoch=0, two_stage=False, weight_decay=0.0001, with_box_refine=False)\n",
      "W0528 15:18:27.411345  6745 device_context.cc:362] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.0, Runtime API Version: 10.1\n",
      "W0528 15:18:27.416965  6745 device_context.cc:372] device: 0, cuDNN Version: 7.6.\n",
      "585 585\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py:687: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  elif dtype == np.bool:\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/tensor/creation.py:143: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if data.dtype == np.object:\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/math_op_patch.py:238: UserWarning: The dtype of left and right variables are not the same, left dtype is VarType.FP32, but right dtype is VarType.INT64, the right dtype will convert to VarType.FP32\n",
      "  format(lhs_dtype, rhs_dtype, lhs_dtype))\n",
      "[1, 300, 91] Tensor(shape=[1, 300, 91], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[[-9.61777592, -5.23012781, -7.39795256, ..., -6.38930178, -7.09633255, -7.50858736],\n",
      "         [-9.94636154, -5.64363098, -8.31368828, ..., -5.95533562, -8.12176132, -7.33026886],\n",
      "         [-7.94795227, -4.43478775, -6.03131390, ..., -6.05372667, -7.74171019, -6.53849077],\n",
      "         ...,\n",
      "         [-8.87540054, -4.96768570, -5.89458275, ..., -6.08922911, -7.09917927, -7.10277462],\n",
      "         [-9.35561562, -5.48900843, -7.24544954, ..., -6.18922234, -7.82873631, -7.50283337],\n",
      "         [-8.69095612, -3.91140795, -5.74481487, ..., -5.53037357, -7.99577999, -6.41766071]]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%cd ~/my_df_detr\n",
    "!python model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 损失以及后处理对齐\n",
    "\n",
    "对于相同的模型输入，在torch和paddle下分别对比，结果基本一致。\n",
    "\n",
    "**troch输出如下:**\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/bbfca0aab066400cb56c070e8ac70b8f6c77793327584692bffcb6aafa1cffef)\n",
    "\n",
    "**paddle输出如下**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/my_df_detr\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:26: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def convert_to_list(value, n, name, dtype=np.int):\n",
      "Compiling user custom op, it will cost a few seconds.....\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:26: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def convert_to_list(value, n, name, dtype=np.int):\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:77: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  return (isinstance(seq, collections.Sequence) and\n",
      "Namespace(aux_loss=True, backbone='resnet50', batch_size=1, bbox_loss_coef=5, cache_mode=False, clip_max_norm=0.1, cls_loss_coef=2, coco_panoptic_path=None, coco_path='/home/aistudio/data/data7122', dataset_file='coco', dec_layers=6, dec_n_points=4, device='cuda', dice_loss_coef=1, dilation=False, dim_feedforward=1024, dropout=0.1, enc_layers=6, enc_n_points=4, epochs=5, eval=True, focal_alpha=0.25, frozen_weights=None, giou_loss_coef=2, hidden_dim=256, lr=0.0002, lr_backbone=2e-05, lr_backbone_names=['backbone.0'], lr_drop=40, lr_drop_epochs=None, lr_linear_proj_mult=0.1, lr_linear_proj_names=['reference_points', 'sampling_offsets'], mask_loss_coef=1, masks=False, nheads=8, num_feature_levels=4, num_queries=300, num_workers=0, output_dir='', position_embedding='sine', position_embedding_scale=6.283185307179586, remove_difficult=False, resume='r50_deformable_detr-checkpoint.pth', seed=42, set_cost_bbox=5, set_cost_class=2, set_cost_giou=2, sgd=False, start_epoch=0, two_stage=False, weight_decay=0.0001, with_box_refine=False)\n",
      "W0528 15:23:44.275153  7774 device_context.cc:362] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.0, Runtime API Version: 10.1\n",
      "W0528 15:23:44.280506  7774 device_context.cc:372] device: 0, cuDNN Version: 7.6.\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/tensor/creation.py:143: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if data.dtype == np.object:\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/math_op_patch.py:238: UserWarning: The dtype of left and right variables are not the same, left dtype is VarType.FP32, but right dtype is VarType.INT64, the right dtype will convert to VarType.FP32\n",
      "  format(lhs_dtype, rhs_dtype, lhs_dtype))\n",
      "loss value:  47.783188\n",
      "scores [100] Tensor(shape=[100], dtype=float32, place=CUDAPlace(0), stop_gradient=True,\n",
      "       [0.23878087, 0.21241456, 0.12337094, 0.09647775, 0.09222054, 0.07936595, 0.07911368, 0.07797299, 0.07245471, 0.07159339, 0.06892633, 0.06629230, 0.06514741, 0.06492331, 0.06386835, 0.06375692, 0.06248840, 0.06108852, 0.05714343, 0.05679127, 0.05635584, 0.05604052, 0.05322877, 0.05175047, 0.05152941, 0.05087387, 0.05033937, 0.04989142, 0.04971807, 0.04971572, 0.04962141, 0.04911161, 0.04906495, 0.04826644, 0.04736077, 0.04680533, 0.04515949, 0.04392244, 0.04359543, 0.04350511, 0.04323424, 0.04323180, 0.04320600, 0.04274516, 0.04212898, 0.04211617, 0.04203331, 0.04096798, 0.04095663, 0.04061569, 0.04035023, 0.03965592, 0.03938908, 0.03932559, 0.03910362, 0.03904319, 0.03894873, 0.03826563, 0.03822044, 0.03816418, 0.03811896, 0.03765899, 0.03701540, 0.03696412, 0.03689187, 0.03578029, 0.03576512, 0.03576318, 0.03573260, 0.03565447, 0.03557934, 0.03525990, 0.03525899, 0.03517071, 0.03498434, 0.03473420, 0.03450697, 0.03439469, 0.03432852, 0.03419359, 0.03411942, 0.03403473, 0.03402211, 0.03398812, 0.03393302, 0.03393029, 0.03364093, 0.03328167, 0.03311764, 0.03286232, 0.03285864, 0.03281115, 0.03270158, 0.03267267, 0.03263281, 0.03262061, 0.03259248, 0.03252637, 0.03250880, 0.03234226])\n",
      "labels [100] Tensor(shape=[100], dtype=int64, place=CUDAPlace(0), stop_gradient=True,\n",
      "       [59, 67, 59, 9 , 59, 67, 42, 9 , 67, 85, 9 , 59, 9 , 15, 16, 9 , 59, 79, 9 , 42, 59, 42, 67, 49, 85, 59, 42, 16, 42, 46, 42, 16, 59, 79, 16, 59, 42, 59, 61, 9 , 59, 9 , 16, 46, 16, 16, 59, 16, 9 , 49, 15, 59, 42, 42, 67, 67, 49, 1 , 1 , 59, 16, 59, 1 , 59, 9 , 51, 16, 59, 11, 67, 1 , 1 , 1 , 16, 42, 16, 16, 1 , 59, 67, 1 , 1 , 67, 59, 51, 9 , 67, 9 , 1 , 9 , 61, 49, 67, 9 , 59, 67, 59, 59, 59, 9 ])\n",
      "boxes [100, 4] Tensor(shape=[100, 4], dtype=float32, place=CUDAPlace(0), stop_gradient=True,\n",
      "       [[ 0.30532837 ,  0.64919603 , 640.27947998, 427.52413940],\n",
      "        [-0.03814697 ,  0.12002778 , 639.94921875, 426.92477417],\n",
      "        [ 5.90270996 , 415.79650879, 645.66296387, 426.75610352],\n",
      "        [ 5.90270996 , 415.79650879, 645.66296387, 426.75610352],\n",
      "        [-0.03814697 ,  0.12002778 , 639.94921875, 426.92477417],\n",
      "        [ 0.02502441 , 361.07901001, 640.02307129, 428.80963135],\n",
      "        [ 5.90270996 , 415.79650879, 645.66296387, 426.75610352],\n",
      "        [110.26275635, 422.32366943, 614.27740479, 427.00082397],\n",
      "        [ 5.90270996 , 415.79650879, 645.66296387, 426.75610352],\n",
      "        [-0.03814697 ,  0.12002778 , 639.94921875, 426.92477417],\n",
      "        [ 81.78920746, 421.62518311, 545.94042969, 426.90585327],\n",
      "        [ 0.73684692 , 186.06370544, 640.68060303, 428.05999756],\n",
      "        [ 55.64754486, 421.56390381, 609.52557373, 426.97268677],\n",
      "        [-0.03814697 ,  0.12002778 , 639.94921875, 426.92477417],\n",
      "        [ 0.30532837 ,  0.64919603 , 640.27947998, 427.52413940],\n",
      "        [ 47.45157242, 421.55236816, 518.37927246, 426.79882812],\n",
      "        [127.37045288,  0.06943083 , 636.57128906, 426.86425781],\n",
      "        [-0.03814697 ,  0.12002778 , 639.94921875, 426.92477417],\n",
      "        [213.81808472, 423.63708496, 593.63055420, 427.01995850],\n",
      "        [110.26275635, 422.32366943, 614.27740479, 427.00082397],\n",
      "        [ 0.02502441 , 361.07901001, 640.02307129, 428.80963135],\n",
      "        [ 81.78920746, 421.62518311, 545.94042969, 426.90585327],\n",
      "        [ 0.73684692 , 186.06370544, 640.68060303, 428.05999756],\n",
      "        [ 5.90270996 , 415.79650879, 645.66296387, 426.75610352],\n",
      "        [ 0.30532837 ,  0.64919603 , 640.27947998, 427.52413940],\n",
      "        [110.26275635, 422.32366943, 614.27740479, 427.00082397],\n",
      "        [126.51741028, 423.17608643, 623.73632812, 427.12686157],\n",
      "        [446.42529297, 425.21255493, 512.33898926, 427.13467407],\n",
      "        [ 47.45157242, 421.55236816, 518.37927246, 426.79882812],\n",
      "        [ 0.30532837 ,  0.64919603 , 640.27947998, 427.52413940],\n",
      "        [ 55.64754486, 421.56390381, 609.52557373, 426.97268677],\n",
      "        [304.02120972, 425.22463989, 375.91253662, 427.11904907],\n",
      "        [ 55.64754486, 421.56390381, 609.52557373, 426.97268677],\n",
      "        [ 5.90270996 , 415.79650879, 645.66296387, 426.75610352],\n",
      "        [265.90393066, 425.09780884, 336.67294312, 427.15463257],\n",
      "        [ 81.78920746, 421.62518311, 545.94042969, 426.90585327],\n",
      "        [213.81808472, 423.63708496, 593.63055420, 427.01995850],\n",
      "        [126.51741028, 423.17608643, 623.73632812, 427.12686157],\n",
      "        [ 0.30532837 ,  0.64919603 , 640.27947998, 427.52413940],\n",
      "        [126.51741028, 423.17608643, 623.73632812, 427.12686157],\n",
      "        [ 0.70592880 ,  85.92160797, 640.58923340, 423.30416870],\n",
      "        [425.19561768, 424.95526123, 581.69702148, 427.00982666],\n",
      "        [403.30914307, 425.27261353, 480.52685547, 427.02474976],\n",
      "        [-0.03814697 ,  0.12002778 , 639.94921875, 426.92477417],\n",
      "        [551.00726318, 425.28091431, 604.19329834, 427.09603882],\n",
      "        [-0.03814697 ,  0.12002778 , 639.94921875, 426.92477417],\n",
      "        [ 38.47932816, 421.39184570, 675.45257568, 427.11141968],\n",
      "        [379.26528931, 425.43051147, 452.93579102, 427.12445068],\n",
      "        [ 42.44565964, 421.51541138, 442.75085449, 426.88400269],\n",
      "        [ 0.02502441 , 361.07901001, 640.02307129, 428.80963135],\n",
      "        [ 5.90270996 , 415.79650879, 645.66296387, 426.75610352],\n",
      "        [ 47.45157242, 421.55236816, 518.37927246, 426.79882812],\n",
      "        [ 38.47932816, 421.39184570, 675.45257568, 427.11141968],\n",
      "        [-0.34694672 , 420.64059448, 637.23577881, 427.04281616],\n",
      "        [ 92.86962891, 418.76510620, 663.58227539, 427.27111816],\n",
      "        [ 0.70592880 ,  85.92160797, 640.58923340, 423.30416870],\n",
      "        [ 0.30532837 ,  0.64919603 , 640.27947998, 427.52413940],\n",
      "        [ 5.90270996 , 415.79650879, 645.66296387, 426.75610352],\n",
      "        [ 81.78920746, 421.62518311, 545.94042969, 426.90585327],\n",
      "        [147.04460144, 154.24375916, 636.63604736, 425.16949463],\n",
      "        [349.47558594, 425.04794312, 428.00564575, 427.04107666],\n",
      "        [-1.14046097 , -0.53656185 , 488.48876953, 426.33145142],\n",
      "        [ 0.30532837 ,  0.64919603 , 640.27947998, 427.52413940],\n",
      "        [213.81808472, 423.63708496, 593.63055420, 427.01995850],\n",
      "        [ 12.47646332, -1.53882861 , 652.47631836,  26.73252869],\n",
      "        [-0.03814697 ,  0.12002778 , 639.94921875, 426.92477417],\n",
      "        [510.39306641, 425.18460083, 577.20672607, 427.05081177],\n",
      "        [-31.49127960, 416.94641113, 607.04217529, 427.08978271],\n",
      "        [-0.03814697 ,  0.12002778 , 639.94921875, 426.92477417],\n",
      "        [ 38.47932816, 421.39184570, 675.45257568, 427.11141968],\n",
      "        [110.26275635, 422.32366943, 614.27740479, 427.00082397],\n",
      "        [ 47.45157242, 421.55236816, 518.37927246, 426.79882812],\n",
      "        [446.42529297, 425.21255493, 512.33898926, 427.13467407],\n",
      "        [212.87048340, 425.12094116, 314.40997314, 427.04693604],\n",
      "        [ 42.44565964, 421.51541138, 442.75085449, 426.88400269],\n",
      "        [164.68142700, 425.35693359, 259.58862305, 427.06149292],\n",
      "        [124.70703125, 425.02532959, 216.08070374, 427.09875488],\n",
      "        [-0.03814697 ,  0.12002778 , 639.94921875, 426.92477417],\n",
      "        [ 93.14598083, 338.86709595, 628.51501465, 433.01162720],\n",
      "        [ 33.57528687, 420.58416748, 673.12292480, 427.09167480],\n",
      "        [551.00726318, 425.28091431, 604.19329834, 427.09603882],\n",
      "        [213.81808472, 423.63708496, 593.63055420, 427.01995850],\n",
      "        [ 55.64754486, 421.56390381, 609.52557373, 426.97268677],\n",
      "        [ 92.86962891, 418.76510620, 663.58227539, 427.27111816],\n",
      "        [ 5.90270996 , 415.79650879, 645.66296387, 426.75610352],\n",
      "        [ 51.12625122, 419.40481567, 375.74444580, 427.19973755],\n",
      "        [293.53543091, 414.44586182, 611.51623535, 428.33068848],\n",
      "        [265.90393066, 425.09780884, 336.67294312, 427.15463257],\n",
      "        [425.19561768, 424.95526123, 581.69702148, 427.00982666],\n",
      "        [-2.34298706 , -2.63790226 , 637.65692139,  36.81598282],\n",
      "        [-0.03814697 ,  0.12002778 , 639.94921875, 426.92477417],\n",
      "        [-0.03814697 ,  0.12002778 , 639.94921875, 426.92477417],\n",
      "        [-31.49127960, 416.94641113, 607.04217529, 427.08978271],\n",
      "        [349.47558594, 425.04794312, 428.00564575, 427.04107666],\n",
      "        [182.47076416, 265.85867310, 639.70123291, 430.49343872],\n",
      "        [127.37045288,  0.06943083 , 636.57128906, 426.86425781],\n",
      "        [105.27416229, 274.27380371, 636.58190918, 428.80627441],\n",
      "        [100.33500671, 159.71160889, 633.86767578, 425.69100952],\n",
      "        [ 42.44565964, 421.51541138, 442.75085449, 426.88400269],\n",
      "        [403.30914307, 425.27261353, 480.52685547, 427.02474976]])\n"
     ]
    }
   ],
   "source": [
    "%cd ~/my_df_detr\n",
    "!python model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 训练对齐\n",
    "\n",
    "固定输入和权重， 因为权重固定起来比较麻烦，这里让paddle和torch加载相同的预训练权重进行对比， 二者输出的loss仍有些差异，后面继续优化\n",
    "\n",
    "**torch输出：**\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/3756b709b2db44289fa74a1baf8d4a057f7c2eb7873946cd92c3fe58fbfe7987)\n",
    "\n",
    "\n",
    "**注意这里学习率是按照网络层设置的不一样，导致训练loss对齐会有问题。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/aistudio/my_df_detr\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:26: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def convert_to_list(value, n, name, dtype=np.int):\n",
      "/home/aistudio/my_df_detr/deformable_transformer.py:138: DeprecationWarning: invalid escape sequence \\s\n",
      "  \"\"\"\n",
      "Compiling user custom op, it will cost a few seconds.....\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:26: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def convert_to_list(value, n, name, dtype=np.int):\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:77: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  return (isinstance(seq, collections.Sequence) and\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py:107: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import MutableMapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable, Mapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sized\n",
      "Namespace(aux_loss=True, backbone='resnet50', batch_size=1, bbox_loss_coef=5, cache_mode=False, clip_max_norm=0.1, cls_loss_coef=2, coco_panoptic_path=None, coco_path='/home/aistudio/data/data7122', dataset_file='coco', dec_layers=6, dec_n_points=4, device='cuda', dice_loss_coef=1, dilation=False, dim_feedforward=1024, dropout=0.1, enc_layers=6, enc_n_points=4, epochs=5, eval=False, focal_alpha=0.25, frozen_weights=None, giou_loss_coef=2, hidden_dim=256, lr=0.0002, lr_backbone=2e-05, lr_backbone_names=['backbone.0'], lr_drop=40, lr_drop_epochs=None, lr_linear_proj_mult=0.1, lr_linear_proj_names=['reference_points', 'sampling_offsets'], mask_loss_coef=1, masks=False, nheads=8, num_feature_levels=4, num_queries=300, num_workers=0, output_dir='', position_embedding='sine', position_embedding_scale=6.283185307179586, remove_difficult=False, resume='r50_deformable_detr-checkpoint.pth', seed=42, set_cost_bbox=5, set_cost_class=2, set_cost_giou=2, sgd=False, start_epoch=0, two_stage=False, weight_decay=0.0001, with_box_refine=False)\n",
      "W0528 19:53:05.111194  3998 device_context.cc:362] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.0, Runtime API Version: 10.1\n",
      "W0528 19:53:05.116741  3998 device_context.cc:372] device: 0, cuDNN Version: 7.6.\n",
      "Epoch 0: StepDecay set learning rate to 0.0002.\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/tensor/creation.py:143: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if data.dtype == np.object:\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/framework.py:687: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  elif dtype == np.bool:\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/fluid/dygraph/math_op_patch.py:238: UserWarning: The dtype of left and right variables are not the same, left dtype is VarType.FP32, but right dtype is VarType.INT64, the right dtype will convert to VarType.FP32\n",
      "  format(lhs_dtype, rhs_dtype, lhs_dtype))\n",
      "epoch: 0, batch_id: 0, loss: 11.404985427856445\n",
      "epoch: 1, batch_id: 0, loss: 10.184232711791992\n",
      "epoch: 2, batch_id: 0, loss: 9.70871639251709\n",
      "epoch: 3, batch_id: 0, loss: 9.461894035339355\n",
      "epoch: 4, batch_id: 0, loss: 9.328996658325195\n"
     ]
    }
   ],
   "source": [
    "%cd ~/my_df_detr\n",
    "!python train_val.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 总结\n",
    "\n",
    "模型已经大体复现，还有诸多不足\n",
    "- 某些步骤消耗显存相比torch太多， 需要优化\n",
    "- 对多batch的支持，没有充分验证\n",
    "- 还没有嵌入到高层API或者PaddleDetection套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!git clone https://github.com.cnpmjs.org/PaddlePaddle/PaddleDetection -b release/2.0 --depth 1\r\n",
    "#%cd work/PaddleDetection\r\n",
    "#!python tools/dfdetr_train.py  -c configs/deformable_detr.yml\r\n",
    "\r\n",
    "#bug1: outputs['pred_logits'] 出现nan\r\n",
    "#bug2： 裁剪box时出现问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
